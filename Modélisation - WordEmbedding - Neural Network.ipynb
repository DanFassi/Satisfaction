{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6975e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49441607",
   "metadata": {},
   "source": [
    "- Importation des modules\n",
    "- Chargement du fichier de données et retraitement du fichier de données\n",
    "- Transformation du DataFrame des MetaDonnée en Matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34468dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numba import jit\n",
    "from keras.layers import LSTM, Activation, Dropout, Dense, Input, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "\n",
    "df = pd.read_csv(\"Data_Satisfaction_retraitement3.csv\")\n",
    "\n",
    "df = df.dropna(axis = 0, how = \"all\", subset =[\"Commentaires_reduit\"]).reset_index()\n",
    "\n",
    "y = df[\"star\"]\n",
    "#Com_Matrix = df[\"Commentaires_reduit\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9bf570",
   "metadata": {},
   "source": [
    "- intégration des commentaire dans une liste\n",
    "- décalage des valeurs de y pour y inclure 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc31e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_commentaires = []\n",
    "for i in range(len(df.Commentaires_reduit)):\n",
    "      liste_commentaires.append(df.Commentaires_reduit[i])\n",
    "y = y.replace(to_replace = [1,2,3,4,5], value = [0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e9631",
   "metadata": {},
   "source": [
    "création d'un ensemble de test et d'un ensemble d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181935ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,Y_train, Y_test = train_test_split(liste_commentaires, y, test_size=0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6573072",
   "metadata": {},
   "source": [
    "Tokenization des mots contenue dans X_train et affichage de l'index de chaque mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "938883dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=50000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "words_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fbc0b9",
   "metadata": {},
   "source": [
    "Création d'une fonction permant la lecture du fichier Glove pre-entrainé et la création d'un dictionnaire contenant l'ensemble des mots du fichier ainsi que leur vecteur associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb0e75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vector(glove_vec):\n",
    "    f = open(glove_vec, 'r', encoding='UTF-8')\n",
    "    word_to_vec_map = {}\n",
    "    for line in f:\n",
    "        w_line = line.split()\n",
    "        curr_word = w_line[0]\n",
    "        word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "\n",
    "    return word_to_vec_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adfc4a5",
   "metadata": {},
   "source": [
    "lecture du fichier Glove , et determination d'une taille de commentaire maximale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c258f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_map = read_glove_vector('glove.twitter.27B.50d.txt')\n",
    "\n",
    "maxLen = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8c44e0",
   "metadata": {},
   "source": [
    "Création d'une matrice d'emmbeding à l'aide du dictionnaire Glove crée plus haut. Si un mot n'est pas présent dans le dictionnaire, un vecteur nul est affecté à la place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b20d861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(words_to_index)+1\n",
    "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
    "\n",
    "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
    "\n",
    "for word, index in words_to_index.items():\n",
    "    embedding_vector = word_to_vec_map.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        emb_matrix[index, :] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d895624",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vocab_len)\n",
    "arr = emb_matrix\n",
    "print(f\"number of zeros: {(arr.size - np.count_nonzero(arr))/50}\")\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28407fd4",
   "metadata": {},
   "source": [
    "Definition d'une fonction permettant de crée un model en fonction de la taille générique des commentaires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab4973b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def commentaires_rating(input_shape):\n",
    "    X_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(X_indices)\n",
    "    X = LSTM(128)(embeddings)\n",
    "    X = Dropout(0.6)(X)\n",
    "    X = LSTM(128)(embeddings)\n",
    "    X = Dropout(0.6)(X)\n",
    "    X = Dense(64, activation='relu')(X)\n",
    "    X = Dense(5, activation='softmax')(X)\n",
    "    model = Model(inputs=X_indices, outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9348f6f7",
   "metadata": {},
   "source": [
    "Padding des données d'entrainement, c'est à dire redimmensionnement de la taille des commentaires pour que tous aient une longueur maximale correspondant à la valeur maxLen définit plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b6dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c76d62",
   "metadata": {},
   "source": [
    "Création de deux fonctions de call back : l'une pour affiné progressivement le learning rate, et l'autre pour arreter le model lorsque plus aucune augmentation significative de la précision est enregistré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c7bd247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reducelr = ReduceLROnPlateau(monitor = 'accuracy',\n",
    "                        min_delta = 0.001,\n",
    "                        patience = 2,\n",
    "                        factor = 0.5, \n",
    "                        cooldown = 2,\n",
    "                        verbose = 1)\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "earlystop = EarlyStopping(monitor = 'accuracy',\n",
    "                    min_delta = 0.0001,\n",
    "                    patience = 4,\n",
    "                    verbose = 1,\n",
    "                    restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc803b",
   "metadata": {},
   "source": [
    "Création du model adapté à des commentaires de taille (nombre de caractères) Maxlen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdb10b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = commentaires_rating((maxLen,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e286945c",
   "metadata": {},
   "source": [
    "Configuration de l'optimizer, compilation et entrainement du model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "436b937b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "355/355 [==============================] - 33s 90ms/step - loss: 2.8033 - accuracy: 0.3287 - val_loss: 1.5065 - val_accuracy: 0.2874 - lr: 1.0000\n",
      "Epoch 2/15\n",
      "355/355 [==============================] - 31s 87ms/step - loss: 1.5305 - accuracy: 0.3243 - val_loss: 1.5025 - val_accuracy: 0.3621 - lr: 1.0000\n",
      "Epoch 3/15\n",
      "355/355 [==============================] - ETA: 0s - loss: 1.5174 - accuracy: 0.3202\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "355/355 [==============================] - 31s 86ms/step - loss: 1.5174 - accuracy: 0.3202 - val_loss: 1.4993 - val_accuracy: 0.3621 - lr: 1.0000\n",
      "Epoch 4/15\n",
      "355/355 [==============================] - 29s 83ms/step - loss: 1.5068 - accuracy: 0.3566 - val_loss: 1.4993 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 5/15\n",
      "355/355 [==============================] - 30s 85ms/step - loss: 1.5068 - accuracy: 0.3566 - val_loss: 1.4993 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 6/15\n",
      "355/355 [==============================] - 30s 85ms/step - loss: 1.5068 - accuracy: 0.3566 - val_loss: 1.4993 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 7/15\n",
      "355/355 [==============================] - 33s 92ms/step - loss: 1.5068 - accuracy: 0.3566 - val_loss: 1.4993 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 8/15\n",
      "355/355 [==============================] - ETA: 0s - loss: 1.5068 - accuracy: 0.3566Restoring model weights from the end of the best epoch: 4.\n",
      "355/355 [==============================] - 32s 89ms/step - loss: 1.5068 - accuracy: 0.3566 - val_loss: 1.4993 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 8: early stopping\n"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate = 1)\n",
    "model1.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'], )\n",
    "\n",
    "m1_history = model1.fit(X_train_indices, Y_train, batch_size=30, epochs=15, validation_split = 0.2, callbacks= [reducelr,earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc3a67",
   "metadata": {},
   "source": [
    "Au bout de 10 époch , on obtient une valeur de validation accuracy de 0.3621, sans aucune augmentation signigicative entre les épochs.\n",
    "\n",
    "Le modèle définit ne se montre pas efficace pour prédire les notes en fonction des commentaires. \n",
    "\n",
    "Essayons avec un autre model, basé sur les matrice convolutives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "504ea841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d_model(input_shape):\n",
    "    X_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(X_indices)\n",
    "    X = Conv1D(512,3,activation='relu')(embeddings)\n",
    "    X = MaxPooling1D(3)(X)\n",
    "    X = Conv1D(256,3,activation='relu')(X)\n",
    "    X = MaxPooling1D(3)(X)\n",
    "    X = Conv1D(256,3,activation='relu')(X)\n",
    "    X = Dropout(0.8)(X)\n",
    "    X = MaxPooling1D(3)(X)\n",
    "    X = GlobalMaxPooling1D()(X)\n",
    "    X = Dense(256, activation='relu')(X)\n",
    "    X = Dense(5, activation='softmax')(X)\n",
    "    model = Model(inputs=X_indices, outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "251bb18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = conv1d_model((maxLen,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb1758bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "355/355 [==============================] - 19s 52ms/step - loss: 34530696.0000 - accuracy: 0.3310 - val_loss: 1.4779 - val_accuracy: 0.2874 - lr: 1.0000\n",
      "Epoch 2/15\n",
      "355/355 [==============================] - 17s 49ms/step - loss: 1.5158 - accuracy: 0.3298 - val_loss: 1.5271 - val_accuracy: 0.2874 - lr: 1.0000\n",
      "Epoch 3/15\n",
      "355/355 [==============================] - ETA: 0s - loss: 1.5171 - accuracy: 0.3159\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "355/355 [==============================] - 18s 52ms/step - loss: 1.5171 - accuracy: 0.3159 - val_loss: 1.4573 - val_accuracy: 0.3621 - lr: 1.0000\n",
      "Epoch 4/15\n",
      "355/355 [==============================] - 18s 50ms/step - loss: 1.4708 - accuracy: 0.3566 - val_loss: 1.4573 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 5/15\n",
      "355/355 [==============================] - 17s 49ms/step - loss: 1.4708 - accuracy: 0.3566 - val_loss: 1.4573 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 6/15\n",
      "355/355 [==============================] - 17s 48ms/step - loss: 1.4708 - accuracy: 0.3566 - val_loss: 1.4573 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 7/15\n",
      "355/355 [==============================] - 18s 50ms/step - loss: 1.4708 - accuracy: 0.3566 - val_loss: 1.4573 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 8/15\n",
      "355/355 [==============================] - ETA: 0s - loss: 1.4708 - accuracy: 0.3566Restoring model weights from the end of the best epoch: 4.\n",
      "355/355 [==============================] - 17s 47ms/step - loss: 1.4708 - accuracy: 0.3566 - val_loss: 1.4573 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 8: early stopping\n"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate = 1)\n",
    "model2.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'], )\n",
    "\n",
    "m2_history = model2.fit(X_train_indices, Y_train, batch_size=30, epochs=15, validation_split = 0.2, callbacks= [reducelr,earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6048617",
   "metadata": {},
   "source": [
    "Au bout de 10 époch , on obtient une valeur de validation accuracy de 0.3621, sans aucune augmentation significative entre les épochs.\n",
    "\n",
    "Ce modèle ne se montre pas plus éfficace que le précédent pour prédire les notes en fonction des commentaires. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4078d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dense_model(input_shape):\n",
    "    X_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(X_indices)\n",
    "    X = GlobalMaxPooling1D()(embeddings)\n",
    "    X = Dense(32, activation='relu')(X)\n",
    "    X = Dense(5, activation='softmax')(X)\n",
    "    model = Model(inputs=X_indices, outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49e98407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 3.2325 - accuracy: 0.3193 - val_loss: 1.5060 - val_accuracy: 0.3621 - lr: 1.0000\n",
      "Epoch 2/15\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 1.5267 - accuracy: 0.3208 - val_loss: 1.5166 - val_accuracy: 0.3621 - lr: 1.0000\n",
      "Epoch 3/15\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 1.5222 - accuracy: 0.3212 - val_loss: 1.5200 - val_accuracy: 0.3621 - lr: 1.0000\n",
      "Epoch 4/15\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 1.5168 - accuracy: 0.3320 - val_loss: 1.4902 - val_accuracy: 0.3621 - lr: 1.0000\n",
      "Epoch 5/15\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 1.5338 - accuracy: 0.3221 - val_loss: 1.5314 - val_accuracy: 0.3621 - lr: 1.0000\n",
      "Epoch 6/15\n",
      "348/355 [============================>.] - ETA: 0s - loss: 1.5161 - accuracy: 0.3205\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 1.5177 - accuracy: 0.3205 - val_loss: 1.4620 - val_accuracy: 0.3621 - lr: 1.0000\n",
      "Epoch 7/15\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 1.4758 - accuracy: 0.3566 - val_loss: 1.4620 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 8/15\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 1.4758 - accuracy: 0.3566 - val_loss: 1.4620 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 9/15\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 1.4758 - accuracy: 0.3566 - val_loss: 1.4620 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 10/15\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 1.4758 - accuracy: 0.3566 - val_loss: 1.4620 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 11/15\n",
      "345/355 [============================>.] - ETA: 0s - loss: 1.4775 - accuracy: 0.3558Restoring model weights from the end of the best epoch: 7.\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 1.4758 - accuracy: 0.3566 - val_loss: 1.4620 - val_accuracy: 0.3621 - lr: 0.0000e+00\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "model3 = Dense_model((maxLen,))\n",
    "adam = keras.optimizers.Adam(learning_rate = 1)\n",
    "model3.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'], )\n",
    "\n",
    "m3_history = model3.fit(X_train_indices, Y_train, batch_size=30, epochs=15, validation_split = 0.2, callbacks= [reducelr,earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fea86e",
   "metadata": {},
   "source": [
    "Au bout de 10 époch , on obtient une valeur maximal de validation accuracy de 0.3621, sans aucune augmentation significative entre les épochs.\n",
    "\n",
    "Ce modèle ne se montre pas plus éfficace que le précédent pour prédire les notes en fonction des commentaires. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
